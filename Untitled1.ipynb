{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMfn5YrxPbPN",
        "outputId": "aa3a4af6-6623-4237-cd78-0fd48c593505"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os, glob\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import PIL"
      ],
      "metadata": {
        "id": "S5MrOly7Pk27"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_arr = []\n",
        "image_dir = '/content/drive/MyDrive/Input Data/images/'\n",
        "image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
        "for image_file in image_files:\n",
        "  with PIL.Image.open(image_file) as img:\n",
        "      if img.mode =='RGB':\n",
        "        img = img.resize((128, 128))\n",
        "        img_arr.append(np.array(img, dtype=\"float32\") / 255.0)\n"
      ],
      "metadata": {
        "id": "d5VgibT6Py2_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_array = np.array(list(filter(lambda x: x is not None ,img_arr)))"
      ],
      "metadata": {
        "id": "bg79qFrBP2CH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del img_arr"
      ],
      "metadata": {
        "id": "3n_f0ZsXSIgQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(image_array, test_size=0.2, random_state=40)"
      ],
      "metadata": {
        "id": "KSJmuneSP5Jt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding noise to the training images \n",
        "noise_factor = 0.2\n",
        "X_train_noisy = train_data + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=train_data.shape)  \n",
        "X_train_noisy = np.clip(X_train_noisy, 0., 1.)"
      ],
      "metadata": {
        "id": "CRBE2FeeP8If"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding noise to the training images \n",
        "noise_factor = 0.2\n",
        "X_test_noisy = test_data + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=test_data.shape)  \n",
        "X_test_noisy = np.clip(X_test_noisy, 0., 1.)"
      ],
      "metadata": {
        "id": "IuO_Kaa1P-sz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class ConvAutoencoder:\n",
        "    def __init__(self, input_shape):\n",
        "        self.input_shape = input_shape\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "        self.autoencoder = None\n",
        "\n",
        "\n",
        "    def build_encoder(self):\n",
        "        input_img = keras.Input(shape=self.input_shape)\n",
        "\n",
        "        # Encoder Layers\n",
        "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "        # x = layers.add(Dropout(0.25))(x) # adding a dropout layer after the max pooling layer\n",
        "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "        self.encoder = keras.Model(input_img, encoded)\n",
        "        self.encoder.summary()\n",
        "        return encoded.shape[1:]\n",
        "\n",
        "    def build_decoder(self, inputShape):\n",
        "        # Decoder Layers\n",
        "        encoded_input = keras.Input(shape=inputShape)\n",
        "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded_input)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.UpSampling2D((2, 2))(x)\n",
        "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.UpSampling2D((2, 2))(x)\n",
        "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.UpSampling2D((2, 2))(x)\n",
        "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = layers.UpSampling2D((2, 2))(x)\n",
        "        decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "        self.decoder = keras.Model(encoded_input, decoded)\n",
        "        self.decoder.summary()\n",
        "\n",
        "    def build_autoencoder(self):\n",
        "        input_img = keras.Input(shape=self.input_shape)\n",
        "        encoded = self.encoder(input_img)\n",
        "        decoded = self.decoder(encoded)\n",
        "        self.autoencoder = keras.Model(input_img, decoded)\n",
        "        self.autoencoder.summary()\n",
        "\n",
        "        self.autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "    def train(self, x_train, x_test, epochs, batch_size,callbacks):\n",
        "        return self.autoencoder.fit(X_train_noisy,train_data,\n",
        "                             epochs=epochs,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=True,\n",
        "                             callbacks=callbacks,\n",
        "                             validation_data=(X_test_noisy, test_data))\n",
        "\n",
        "    def restore(self, x):\n",
        "        restored_imgs = self.autoencoder.predict(x)\n",
        "        return restored_imgs\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qcif3xlnQCI0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Convolutional Autoencoder\n",
        "autoencoder = ConvAutoencoder(input_shape=train_data.shape[1:])\n",
        "\n",
        "# Build the encoder, decoder and autoencoder\n",
        "outputShape = autoencoder.build_encoder()\n",
        "autoencoder.build_decoder(outputShape)\n",
        "autoencoder.build_autoencoder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO0RpS4yQOI9",
        "outputId": "cbfa9831-86cf-44d8-fd7c-93720bd6e1f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 128, 128, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 128, 128, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 64, 64, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 64, 64, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 8, 8, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29,152\n",
            "Trainable params: 28,896\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 8, 8, 32)]        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 32)          9248      \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8, 8, 32)         128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 16, 16, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSampling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " up_sampling2d_2 (UpSampling  (None, 64, 64, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 64, 64, 32)        9248      \n",
            "                                                                 \n",
            " up_sampling2d_3 (UpSampling  (None, 128, 128, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 128, 128, 3)       867       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,243\n",
            "Trainable params: 38,051\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " model (Functional)          (None, 8, 8, 32)          29152     \n",
            "                                                                 \n",
            " model_1 (Functional)        (None, 128, 128, 3)       38243     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67,395\n",
            "Trainable params: 66,947\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the autoencoder on the training\n",
        "# Train the model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "print('-------Training Starts ---------')\n",
        "checkpoint = ModelCheckpoint(\"ImageRestore Model.h5\", save_best_only=True, save_weights_only=False, verbose=1 )\n",
        "autoencoder.train(X_train_noisy, train_data,  epochs=20, batch_size=32, callbacks=checkpoint )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04ZfQLtlQTiA",
        "outputId": "b133b79e-3587-439d-e467-fd72fdb739b3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------Training Starts ---------\n",
            "Epoch 1/20\n",
            "156/156 [==============================] - ETA: 0s - loss: 0.5764\n",
            "Epoch 1: val_loss improved from inf to 0.65283, saving model to ImageRestore Model.h5\n",
            "156/156 [==============================] - 26s 61ms/step - loss: 0.5764 - val_loss: 0.6528\n",
            "Epoch 2/20\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.5579\n",
            "Epoch 2: val_loss did not improve from 0.65283\n",
            "156/156 [==============================] - 6s 40ms/step - loss: 0.5579 - val_loss: 0.6736\n",
            "Epoch 3/20\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.5536\n",
            "Epoch 3: val_loss improved from 0.65283 to 0.59747, saving model to ImageRestore Model.h5\n",
            "156/156 [==============================] - 7s 42ms/step - loss: 0.5537 - val_loss: 0.5975\n",
            "Epoch 4/20\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.5519\n",
            "Epoch 4: val_loss improved from 0.59747 to 0.55407, saving model to ImageRestore Model.h5\n",
            "156/156 [==============================] - 6s 40ms/step - loss: 0.5519 - val_loss: 0.5541\n",
            "Epoch 5/20\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.5507\n",
            "Epoch 5: val_loss improved from 0.55407 to 0.55308, saving model to ImageRestore Model.h5\n",
            "156/156 [==============================] - 7s 42ms/step - loss: 0.5505 - val_loss: 0.5531\n",
            "Epoch 6/20\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.5490\n",
            "Epoch 6: val_loss did not improve from 0.55308\n",
            "156/156 [==============================] - 6s 40ms/step - loss: 0.5491 - val_loss: 0.5648\n",
            "Epoch 7/20\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.5481\n",
            "Epoch 7: val_loss did not improve from 0.55308\n",
            "156/156 [==============================] - 7s 42ms/step - loss: 0.5481 - val_loss: 0.5532\n",
            "Epoch 8/20\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.5477\n",
            "Epoch 8: val_loss improved from 0.55308 to 0.55269, saving model to ImageRestore Model.h5\n",
            "156/156 [==============================] - 6s 42ms/step - loss: 0.5478 - val_loss: 0.5527\n",
            "Epoch 9/20\n",
            "156/156 [==============================] - ETA: 0s - loss: 0.5469\n",
            "Epoch 9: val_loss did not improve from 0.55269\n",
            "156/156 [==============================] - 7s 42ms/step - loss: 0.5469 - val_loss: 0.5531\n",
            "Epoch 10/20\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.5461\n",
            "Epoch 10: val_loss improved from 0.55269 to 0.54934, saving model to ImageRestore Model.h5\n",
            "156/156 [==============================] - 7s 42ms/step - loss: 0.5462 - val_loss: 0.5493\n",
            "Epoch 11/20\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.5455\n",
            "Epoch 11: val_loss did not improve from 0.54934\n",
            "156/156 [==============================] - 7s 42ms/step - loss: 0.5457 - val_loss: 0.5540\n",
            "Epoch 12/20\n",
            "156/156 [==============================] - ETA: 0s - loss: 0.5450\n",
            "Epoch 12: val_loss improved from 0.54934 to 0.54872, saving model to ImageRestore Model.h5\n",
            "156/156 [==============================] - 7s 43ms/step - loss: 0.5450 - val_loss: 0.5487\n",
            "Epoch 13/20\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.5450\n",
            "Epoch 13: val_loss did not improve from 0.54872\n",
            "156/156 [==============================] - 7s 42ms/step - loss: 0.5449 - val_loss: 0.5507\n",
            "Epoch 14/20\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.5444\n",
            "Epoch 14: val_loss improved from 0.54872 to 0.54700, saving model to ImageRestore Model.h5\n",
            "156/156 [==============================] - 7s 43ms/step - loss: 0.5445 - val_loss: 0.5470\n",
            "Epoch 15/20\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.5443\n",
            "Epoch 15: val_loss did not improve from 0.54700\n",
            "156/156 [==============================] - 7s 42ms/step - loss: 0.5443 - val_loss: 0.5522\n",
            "Epoch 16/20\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.5437\n",
            "Epoch 16: val_loss did not improve from 0.54700\n",
            "156/156 [==============================] - 7s 42ms/step - loss: 0.5438 - val_loss: 0.5482\n",
            "Epoch 17/20\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.5432\n",
            "Epoch 17: val_loss did not improve from 0.54700\n",
            "156/156 [==============================] - 6s 41ms/step - loss: 0.5432 - val_loss: 0.5488\n",
            "Epoch 18/20\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.5429\n",
            "Epoch 18: val_loss improved from 0.54700 to 0.54590, saving model to ImageRestore Model.h5\n",
            "156/156 [==============================] - 7s 43ms/step - loss: 0.5430 - val_loss: 0.5459\n",
            "Epoch 19/20\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.5426\n",
            "Epoch 19: val_loss improved from 0.54590 to 0.54559, saving model to ImageRestore Model.h5\n",
            "156/156 [==============================] - 7s 42ms/step - loss: 0.5426 - val_loss: 0.5456\n",
            "Epoch 20/20\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.5425\n",
            "Epoch 20: val_loss did not improve from 0.54559\n",
            "156/156 [==============================] - 7s 42ms/step - loss: 0.5425 - val_loss: 0.5459\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f49b01b46a0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Use the trained model to restore images\n",
        "# testimg = glob.glob('/content/drive/MyDrive/Input Data/*.jpg')\n",
        "restored_imgs = autoencoder.restore(X_test_noisy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "FG8q6pYuQXG4",
        "outputId": "b8ea0fb7-9866-498b-9967-b6e42f5e100a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bc00f641ea16>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use the trained model to restore images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# testimg = glob.glob('/content/drive/MyDrive/Input Data/*.jpg')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrestored_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_noisy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'autoencoder' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display some sample results\n",
        "import matplotlib.pyplot as plt\n",
        "n = 10  # number of images to display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original images\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(X_test_noisy[i+1200])\n",
        "    plt.title(\"Original\")\n",
        " \n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display restored images\n",
        "    ax = plt.subplot(2, n, i + n + 1)\n",
        "    plt.imshow(restored_imgs[i+1200])\n",
        "    plt.title(\"Restored\")\n",
        "\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)     \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ntz_b3CoQZaT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}